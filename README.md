# Data-Analytics
   # CHAPTER 1 !!!

# Computing with confidence user
-Knows to cope when things go wrong
-Knows how to learn new computing skills independently.
  # Data Analytics skills
-Machine learning 
-data visualization

  # Data Analytic roles:

*Data collection & preparation
* Data Analysis
* Data visualization &storytelling
* Decision support
* Collaboration & communication
* Continuous learning & adaptation
   # Data Analytic Responsibilities :
-Manages the delivery of user satisfaction surveys    & report on results using data visualization software
-Work with business line owners to develop requirements,define success metrics,manage & execute analytical pojects and evaluate results.

-Design,Build,Test & maintain backend code.
   # Steps When approaching a new project
*Define the questions-defining a problem
*Collect data-primary/internal
*Clean the data-prepare& fix the missing data
*Analyze data
*Interprete & share the solution /results
   # PROGRAMMING LANGUAGES
 -SQL, Oracle & Python
 For data analytics to prosper there has to be: Data, Storage & Computing
   # Processes for data analaytics:
-Data acquistion
-Cleaning & manipulation
-Analysis,Visualization,Reporting & Communication
  # Data Analytic Techniques
Descriptive,Predictive & Prescriptive


Artificial intelligence (AI) includes any type of technique where you are attempting to get a computer system to imitate human behavior.
Machine learning (ML) is a subset of AI techniques.
Deep learning is a further subdivision of machine learning that uses quite complex techniques, known as neural networks, to discover knowledge in a particular way. Used for image,video & sound.
Data Governance programs: ensures that the organization has high-data quality & able to effectively control the data
# Analytics tool
Excel or Google sheets

 # CHAPTER 2 !!!!
 # Tools for representing tabular data
*Microsoft Excel
*Google Sheets
*Apple numbers
Connection  between tables-- Relationship
Database softwares: Oracle, Microsoft SQL Server, MySQL & Postgre SQL.

Structured data- organized into row & column
# Data Types:
-Character,text,Alphanumeric,clob &longtext
ASCII- includes upper & lowercase alphabets &numbers
Structured Data
Tabular data is structured data, with values stored in a consistent, defined manner, organized into columns and rows.
Unstructured Data
Unstructured data is qualitative, describing the characteristics of an event or an object.
E.G Binary,Audio,image,video &large text.
Key-unique identifier
Key-Filename
Value- Content of a file

Semi-Structured Data
Semi-structured data is data that has structure and that is not tabular.

# Categories of data
-Quantitive vs Qualitive
-Discrete vs Continous
-Categorical & Dimensional

 # Machine data source:
 -IOT devices,smartphones,tablets, PCs & servers
 # Unstructured data
 includes the KEY & VALUE

   # CHAPTER 3!!! Databases & Data Acquisition
   2 Categories:
   Relational& non-Relational database
 # ERD Cardinalities:
 *One
 *Many
 *One &one only
 *Zero or one
 *One or many
 # Benefits of Relational DB
 -Consistency,Stored procedures,Security& Locking
 ERD- Visual artifact of data modelling process.
 Unary relationship- When an entity has a connection with itself.
 Ternary relationship- connects 3 entities. 

 # Non-relational DB
 -key value,column store,gragh & dicument store.
 # Benefits of Non-Relational DB
 -Flexibility,Scalability & cost effictiveness.
 # Data base uses cases
 # Categories of Data Processing
 *OLTP- transfer encounters for everyday
 *OLAP- ability of organizations to analyze data using relational DB.

 # Normalization: process of minimizing the duplicates
 # 1NF -first Normal Form: 
 When a row in a table is unique & column contains unique values.
 # SCHEMA: 
 defines how data is organized within a relational DB
 
 # Data Mart:
 Subset of data warehouse
 # Data Lake:
 Capture any type of data. It store raw data & more complex than data warehouse or data mart.
  # Inner join statements
  Meaning there should be a table
  OLAP: denormalized
  OLTP:normalized
  # Dimensionality
  Refers to the number of attributes a table has. Higher attributes- higher dimensionality.

  SQL Keywords:
  CREATE
  READ
  UPDATE
  DELETE
  STDDEV
   # Chapte4 !!!!!
Missing values: issue that impacts data quality( null values)
Invalid:
-Values outside the valid range of a given attribute
Nonparametric data:
-Data collected from categorical variables
Data Outliers:
-Value that differs significantly from other pbservations in a dataset.
# Techniques for data analytics
*Recording data:
-Technique to map original values for a variable into a new value.
*Derived variable
*Data merge
*Data blending
*Concatenation
*Data append
*Imputation: replacing missing values

# Approaches used for imputing values:
-Remove missing data
-replace with zero
-Replace with overall average
-Replace with closest frequent mode
-Closest value average

Reduction: process of shrinking an extensive dataset.
*Dimensionality- removes attributes from a datset.
*Numerosity- reduces the overall volume of data.
# Data aggregation:
Summary of raw data for analysis

Transposition:
-turning row into column/ column into rows
Normalization:
-converts data from different scales to the same scale
min-max normalization- approach to normalizing data.

# SQL FUNCTIONS:
-Count, Min, Max, AVG, Sum, STDDEV
Automated validation
-Validating data automatically to avoid human errors. It does validation checks.
# Data Quality dimensions
-measures the attributes of data which can be individualyy assessed,interpreted & improved.

  # CHAPTER 5 !!!!!--Data Analysis & Statistic
  # Fundamentals of statistics
  -Population: represents all the data subjects that you want to analyze.
  -Variable- unique attribute of data subject.
   # Unvariate analysis
   -When exploring the characteristic of a single variable .
   # Observation
   -Individual record in a dataset corresponding to a tabular data row.
   # STATISTICS
   -It's all about exploring numbers & performing calculations.Coolection & interpetation of data.
   -Symbols for Statistics- used to convey meaning.
   # Major concepts of Stats
   * Descriptive & Inferential
     Descriptive: getting data &talk about it.
     Inferential: taking & analyzing data

  # Uses of Statistics
  -To measure & analyze data.
  Total number of things called SAMPLE SIZE

  Variable can be: measurable, countable & categorized.
  # Two types of data in Stats:
  -Quantitative data : measured in numbers . E.G height , weight etc.
  Types of Quantitative data:
  *Discrete: Numbers that can be measured. E.G One can own car or more
  *Continous: It can take decimal numbers like 24.5
  
  -Categorical data: values that are placed in different groups /categories. E.G hair colour( blond,black etc)
  Types of Categorical data
  *Categorical & ordinal: variables are in order
  *Categorical & Nominal: variables are not in order.

   # Descriptive Statistics:
   -Branch of statistics that summarizes & describe data.
   Counts- counts the total.
   Percentage- frequency measure that identifies the proportion of a given value for a variable with respect to the total number of rows in a dataset.
   Frquency- describes how often a specific value for a variable occurs in a dataset.
   # Range= max-min (difference between maximum & minimum)
   Distribution- Function that illustrates probable values for a variable & its frequency.
   IQR- Combination of 2nd & 3rd quantile range.

   # Normal distribution 
   -type of continous probability distribution
   CLT Central Limit theorem-theorem for statistic analysis.
   # Skewed distribution
   -asymmetric shape with a single peak & long tail on one side have different sides.
   # Bimodal distribution
   -has two distinct nodes. Multimodal has multiple distinct nodes.

   # Variance
   -Expected value of the squared deviation from the mean.It calculates how far the values are from the mean value.
   #  Standard deviation 
     -statistic that measures dispersion in terms of how far values of a variable are from its mean.
     Standard Normal Distribution/Z-distribution:
     Special Normal Distribution with a mean of 0 & STDDEV of 1. T-distribution also has a mean of 0.
     
   # Inferential Statistics:
   -Branch od statistics that uses sample data to draw conclusions.
   -The standard Error- tool to measure the standard deviatio of the distribution of mean of a given sample size.
   # standard Error: population standard deviation/ square root of the sample size
   # Hypothesis statement: only one statement can be true
   Two components for Hypothesis:
   *Null
   -Presumes that there is no effect on the test
   *Alternative
   -Presumes that there is an effect on the test
   # Data analysis
   Exploratory data analysis: uses descriptive stats to summarize the mean.
   # Steps for conduction EDA
   -Check data structure
   -Check data representation
   -Check if data is missing 
   -Identify outliers
   -Summarize stats
   -Check assupmtions
   Degrees of freedom is defined as 1 less than the total 
   E.G 28-1 =27
   left skewed : median is higher than the mean
   right skewed: mean is greater than median

   # CHAPTER 6 !!!!!--Data Analytic tools
   Speadsheet -allow users to create documents that organize any type of data into rows & columns
   Programming Languages:
   -R
   -Python
   -SQL
   SQL sublanguages: DDL & DML
   DDL-- Data Definition Language: defines the structure of DB itself
   DML-- Data Manipulation Language: workswith data inside of a DB. It add, remove & change the data.
   
   DDL Commands:
   -CREATE ,ALTER ,DROP.
   DML commands:
   -SELECT, INSERT, UPDATE, DELETE
   # Azure Data Studio
   -tool to write a DB queries in SQL, send them to the DB & view the results.
   # IBM's SPSS modeler
   One of the popular tool for building graphicalmachine learning models.
   # RapidMiner
   Another graphical machine learning, creating visual designs.

   # Analytical suite
   -provides powerful capabilities that cross all phases of an analytical process, for cleaning data ,visualize,produce models,make predictions,communicate & report the results.
   1. IBM Cognos
      Major components:
      *Cognos connection: offer access to other elements
      *Query studio:data querying
      *Report studio:report design
      *Analysis studio:modeling & analysis
      *Event studio:provide real time data
      *Metric studio:ability to create scorecards
      *cognos viewer: allow stakeholders to easily interact
2. Microsoft power BI
  Major components:
*Power BI desktop- windows app for data analyst, interact with data & publish reports.
*Power BI- Hosts Power BI in the cloud for customers.
*Mobile apps- for power BI of iOS, android & windows.
*Power BI Report builder-where reports are generated.
*Power BI report server-organizations can host their own Power BI environment.
3. MicroStrategy
   -Machine learning &reports can be applied too & building dashboards.
4.Domo
-Data can be analyzed.
5.Datorama
-Focues on a specific components of an organization business like sales &marketing( only)
6. AWS QuickSight
   -has poerful storage,data warehousing,machine learning & AI capabilities offered by Amazon cloud.
7. Tableau
   -for market to identify trends in the data, data visualization.
8. Qlik
   -It has Qlik view(cost effective) & Qlik Sense(advanced) .
9. business Objects
    -For reports & analytical environment for organisations
R language- focuses on solving analytical problems.
SPSS-professional statistical analysis package.

# CHAPTER 7 !!!!!
Data visualization with report & dashboard
Reports & Dashboard-summarizes data for end users.
Reports- statistic electronic or physical documents that reflects info at a given time.
Dashboard-Interactive visualization that encourages people to explore data dynamically.

# APPROACHES :
-Pull-To publish a report to a known location like webpage.
-Push- When report is automatically sent to the appropriate people as it becomes available.
-Blended-informing people that the report is available
# Design principles( 5 Cs) of creating visualizations:
-Control-focus the attention of the audience.
-Correctness-make sure info is accurate.
-Clarity--make sure it's easy to interpret.
-Consistency-using same design & documentation.
-Concentration-using visuals to focus the audience's attention.

Design elements( color schemes, page layout, font size ,style & charts)

Fonts
-Serif font style- include curls
-Sans serif- doesn't include curls
Style guide
-Set of standards that drives consistency in communication
Version number:
-numeric value that refers to a specific version of a report
Static data:
-some regular interval
Continous data
-For daily duties
Wireframe:
-Blue print for an application
# Visualization Types
-Line-Relationship between 2 variables
-Bar-Represents categorical data
-Stacked bar- uses a dot for each observation between 2 numeric variables
-Bubble-Scatterplot where size of each dot depends on a third numeric variables
-Histogram- shows the frequency distribution for numeric data
-Maps-To convey the location
-Infographic-represents information correctly
-Word cloud-uses shape, font size & color to signify relative importance of words
-Scatter-relationship between 2 numeric values

# CHAPTER 8 !!!!: Data Governance

Data Stewardship- Act of developing the policies & procedures for looking after an organization's data quality, security, privacy & regulatory.
Data steward- person responsible for data stewardship, responsible for leading an organization's data governance activities.
Data Owner- senior business leader with overall responsiblity for a specific data.
Data domain- contains data about a particular operational division within an organization.
Subject area works on behalf of Data owner to handle daily tasks.
Data custodian-role given to someone who implements technical controls that execute data governance policies. IT employees who congifure applications, dashboard & databases.
Data classification matrix-Categories, descriptions & disclosure implications for data.
DUA( Data Use Agreement)- document for transferring private data between organizations.
IRB( Institutional Review Board) body that formally reviews & approves any sharin of data.
Encryption- process of encoding data with a key so that only authorized parties can read it. Includes letters, numbers & symbols.
Data in transit- data moving between one location to another
HTTP- used to transmit data over the internet
TLS(Transport Layer Security)- used to ensure data security
# Two protocols
# SEP ( secure copy protocol)& SFTP ( secure file transfer protocol)
-To copy files between transactional & analytical servers.
Data classification- process of analyzing data & organizing  it itno risk-based categories.
PII- Personally identificable information - data that uniquely identify a person .

Criminal law- discourage people from action acting in a way that negatively impacts society.
Civil law- to resolve arguments between individuals,organization & government agencies.
Administrative law- enable the effective operation of government.




   
   
   
  

  
      
  






 
 
   
 




 

